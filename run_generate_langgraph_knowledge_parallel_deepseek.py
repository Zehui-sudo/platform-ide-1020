#!/usr/bin/env python3
"""
LangGraph å­¦ä¹ çŸ¥è¯†å¹¶è¡Œç”Ÿæˆè„šæœ¬ï¼ˆLangGraph ç¼–æ’ + DeepSeek APIï¼‰

ç‰¹æ€§:
- ä½¿ç”¨ LangGraph è¿›è¡Œæµç¨‹ç¼–æ’ï¼ˆåŠ è½½å¤§çº² -> å¹¶è¡Œç”Ÿæˆ -> å®Œæˆï¼‰ã€‚
- é€šè¿‡ DeepSeekï¼ˆOpenAI å…¼å®¹ï¼‰å¼‚æ­¥å®¢æˆ·ç«¯å¹¶å‘ç”Ÿæˆå†…å®¹ã€‚
- ä» web-learner/public/langgraph-learning-path.md è¯»å–å¤§çº²ã€‚
- è¾“å‡ºåˆ° web-learner/public/content ä¸‹ï¼ˆæ¯ä¸ªçŸ¥è¯†ç‚¹ä¸€ä¸ª .md æ–‡ä»¶ï¼‰ã€‚

ä¾èµ–:
  pip install -U openai langgraph tqdm

é…ç½®:
- ä¼˜å…ˆè¯»å–å‘½ä»¤è¡ŒæŒ‡å®šçš„ --configï¼Œé»˜è®¤ config.example.json
- éœ€è¦æä¾› DeepSeek API Key
  - ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY
  - æˆ–é…ç½®æ–‡ä»¶ä¸­çš„ deepseek_api_key
  - base_url é»˜è®¤ä¸º https://api.deepseek.com
  - model é»˜è®¤ä¸º deepseek-chatï¼ˆæˆ–æ ¹æ®éœ€è¦æ”¹ä¸º deepseek-reasonerï¼‰
"""

from __future__ import annotations

import os
import re
import json
import argparse
import asyncio
import logging
from dataclasses import dataclass
from typing import List, Optional, Tuple, Dict, Any
from pathlib import Path
from tqdm.asyncio import tqdm_asyncio

# LangGraph å¯¼å…¥ï¼ˆè‹¥æœªå®‰è£…ç»™å‡ºå‹å¥½æç¤ºï¼‰
try:
    from langgraph.graph import StateGraph, START, END
except Exception:
    raise SystemExit(
        "[é”™è¯¯] æœªæ‰¾åˆ° langgraphã€‚è¯·å…ˆå®‰è£…:\n"
        "  python3 -m pip install -U langgraph\n"
    )


# --- æ—¥å¿—è®¾ç½® ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('langgraph_generation_parallel_deepseek_log.txt', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# --- æ•°æ®ç»“æ„ ---
@dataclass
class KnowledgePoint:
    id: str
    title: str
    level: int
    chapter: str
    section: str


class LangGraphKnowledgeGeneratorDeepSeek:
    def __init__(self, config_path: str = "config.example.json") -> None:
        self.base_dir = Path(__file__).parent.resolve()
        self.config = self._load_config(config_path)

        # è¾“å…¥å¤§çº²
        outline_md = self.base_dir / 'web-learner' / 'public' / 'langgraph-learning-path.md'
        self.outline_content, self.knowledge_points = self._load_points_from_md(outline_md)

        # è¾“å‡ºç›®å½•ï¼ˆæ³¨æ„ï¼šè¦æ±‚å†™å…¥åˆ° public/content æ ¹ç›®å½•ï¼‰
        self.output_dir = self.base_dir / 'web-learner' / 'public' / 'content'
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ– DeepSeek OpenAI å…¼å®¹å¼‚æ­¥å®¢æˆ·ç«¯
        self.client = None
        self._init_async_client()
        # å°èŠ‚å‰ç¼€è¿‡æ»¤ï¼ˆå¦‚ {'3-1'} -> åŒ¹é… lg-sec-3-1-*ï¼‰
        self.group_prefix_filter: Optional[set[str]] = None

    # --- é…ç½®ä¸å®¢æˆ·ç«¯ ---
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        default_config = {
            "api_provider": "deepseek",
            "deepseek_api_key": os.environ.get("DEEPSEEK_API_KEY") or "YOUR_DEEPSEEK_API_KEY_HERE",
            "deepseek_base_url": "https://api.deepseek.com",
            "model": "deepseek-reasoner",
            "temperature": 0.6,
            "max_tokens": 4096,
            "retry_times": 3,
            "retry_delay": 10,
            "max_parallel_requests": 8,
        }

        path = Path(config_path)
        if path.exists():
            try:
                user_cfg = json.loads(path.read_text(encoding='utf-8'))
                default_config.update(user_cfg)
            except Exception:
                logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} è¯»å–å¤±è´¥æˆ–æ ¼å¼é”™è¯¯ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
        else:
            path.write_text(json.dumps(default_config, ensure_ascii=False, indent=2), encoding='utf-8')
            logger.info(f"å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {config_path}ã€‚è¯·å¡«å…¥ DeepSeek API Keyã€‚")

        return default_config

    def _init_async_client(self) -> None:
        try:
            from openai import AsyncOpenAI
        except Exception:
            logger.error("ç¼ºå°‘ openai åº“ï¼Œè¯·å…ˆå®‰è£…: pip install openai")
            return

        api_key = self.config.get("deepseek_api_key") or os.environ.get("DEEPSEEK_API_KEY")
        if not api_key or "YOUR_DEEPSEEK_API_KEY_HERE" in api_key:
            logger.error("DeepSeek API Key æœªè®¾ç½®ã€‚è¯·åœ¨ config æˆ–ç¯å¢ƒå˜é‡ (DEEPSEEK_API_KEY) ä¸­é…ç½®ã€‚")
            return

        base_url = self.config.get("deepseek_base_url", "https://api.deepseek.com")
        # DeepSeek çš„ OpenAI å…¼å®¹æ¥å£åº”å¯ä¸æ ‡å‡† OpenAI SDK ä½¿ç”¨ base_url é…ç½®
        self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)

    # --- å¤§çº²è§£æ ---
    def _load_points_from_md(self, md_path: Path) -> Tuple[str, List[KnowledgePoint]]:
        content = ""
        try:
            content = md_path.read_text(encoding='utf-8')
        except FileNotFoundError:
            logger.error(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¤§çº²æ–‡ä»¶ {md_path}ã€‚")
            return "", []

        points: List[KnowledgePoint] = []
        current_chapter = ""
        current_section = ""

        for line in content.splitlines():
            m_ch = re.search(r"## ç¬¬(\d+)ç« ï¼š(.+?) \(id: (lg-ch-\d+)\)", line)
            if m_ch:
                current_chapter = m_ch.group(2).strip()
                continue

            m_sec = re.search(r"### ([\d\.]+?) (.+?) \(id: (lg-gr-[\d\-]+)\)", line)
            if m_sec:
                current_section = m_sec.group(2).strip()
                continue

            m_pt = re.search(r"#### ([\d\.]+?) (.+?) \(id: (lg-sec-[\d\-a-z_]+)\)", line)
            if m_pt:
                points.append(
                    KnowledgePoint(
                        id=m_pt.group(3),
                        title=m_pt.group(2),
                        level=line.count('#'),
                        chapter=current_chapter,
                        section=current_section,
                    )
                )

        logger.info(f"æˆåŠŸä» {md_path} åŠ è½½äº† {len(points)} ä¸ªçŸ¥è¯†ç‚¹ã€‚")
        return content, points

    # --- Prompt ---
    def _build_prompt(self, point: KnowledgePoint) -> str:
        return f"""
ä½ æ˜¯ä¸€åé¡¶çº§çš„è½¯ä»¶æ¶æ„å¸ˆå’Œ LangGraph ä¸“å®¶ï¼Œæ“…é•¿ç”¨æ¨¡å—åŒ–ã€å¯å¤ç°çš„ä»£ç æ¥è§£é‡Šå¤æ‚çš„å·¥ä½œæµã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä¸º LangGraph å­¦ä¹ è·¯å¾„ä¸­çš„ä¸€ä¸ªç‰¹å®šçŸ¥è¯†ç‚¹ç”Ÿæˆè¯¦ç»†çš„æ•™å­¦å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚

1) å½“å‰çŸ¥è¯†ç‚¹ä¿¡æ¯:
- æ ‡é¢˜: {point.title}
- ID: {point.id}
- æ‰€å±ç« èŠ‚: {point.chapter}
- æ‰€å±å°èŠ‚: {point.section}

2) æ•´ä½“å­¦ä¹ å¤§çº²ä¸Šä¸‹æ–‡:
ä¸ºäº†ç¡®ä¿å†…å®¹ä¸é‡å¤ä¸”æ‰¿ä¸Šå¯ä¸‹ï¼Œè¯·å‚è€ƒä»¥ä¸‹å®Œæ•´çš„ LangGraph å­¦ä¹ å¤§çº²ã€‚å½“å‰è¦ç”Ÿæˆçš„çŸ¥è¯†ç‚¹æ˜¯ {point.title}ã€‚
---
{self.outline_content}
---

3) å†…å®¹ç”Ÿæˆè¦æ±‚:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownç»“æ„ç”Ÿæˆå†…å®¹ã€‚æœ€å…³é”®çš„è¦æ±‚æ˜¯ï¼šæ‰€æœ‰ä»£ç å—éƒ½å¿…é¡»æ˜¯å®Œæ•´ã€å¯ç‹¬ç«‹è¿è¡Œçš„ LangGraph åº”ç”¨ï¼ŒåŒ…å«å¿…è¦çš„ importã€State å®šä¹‰ã€èŠ‚ç‚¹å‡½æ•°ã€å›¾æ„å»ºä¸æ‰§è¡Œã€‚

## {point.title}

### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ
ä¸€å¥è¯è¯´æ˜è¿™ä¸ªçŸ¥è¯†ç‚¹è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œä¸ºä»€ä¹ˆå®ƒæ˜¯æ„å»ºå¤æ‚ Agent æµç¨‹çš„å…³é”®ã€‚

### ğŸ’¡ ä½¿ç”¨æ–¹å¼
ç»™å‡ºæ ¸å¿ƒ API å’ŒåŸºæœ¬ç”¨æ³•ï¼Œå¿…è¦æ—¶é™„ç®€çŸ­ä»£ç ã€‚

### ğŸ“š Level 1: åŸºç¡€è®¤çŸ¥ï¼ˆ30ç§’ç†è§£ï¼‰
æä¾›ä¸€ä¸ªæœ€ç®€å•ä¸”å®Œæ•´å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹ï¼ˆåŒ…å« importã€stateã€nodesã€graphã€runï¼‰ã€‚
```python
# å®Œæ•´ã€å¯è¿è¡Œçš„æœ€å°ç¤ºä¾‹
```

### ğŸ“ˆ Level 2: æ ¸å¿ƒç‰¹æ€§ï¼ˆæ·±å…¥ç†è§£ï¼‰
å±•ç¤º 1-2 ä¸ªå…³é”®ç‰¹æ€§æˆ–é«˜çº§ç”¨æ³•ï¼Œæ¯ä¸ªç‰¹æ€§é…å®Œæ•´ç¤ºä¾‹ä¸è¯´æ˜ã€‚

#### ç‰¹æ€§1: [ç‰¹æ€§åç§°]
```python
# å®Œæ•´ã€å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹
```

### ğŸ” Level 3: å¯¹æ¯”å­¦ä¹ ï¼ˆé¿å…é™·é˜±ï¼‰
å¦‚é€‚ç”¨ï¼Œé€šè¿‡â€œé”™è¯¯ç”¨æ³• vs æ­£ç¡®ç”¨æ³•â€å±•ç¤ºå¸¸è§é™·é˜±ã€‚
```python
# é”™è¯¯ç”¨æ³•
# æ­£ç¡®ç”¨æ³•
```

### ğŸš€ Level 4: å®æˆ˜åº”ç”¨ï¼ˆçœŸå®åœºæ™¯ï¼‰
è®¾è®¡ä¸€ä¸ªå®é™…åœºæ™¯ï¼Œç»¼åˆè¿ç”¨è¯¥çŸ¥è¯†ç‚¹ï¼Œæä¾›å®Œæ•´å¯è¿è¡Œä»£ç å’Œé¢„æœŸè¾“å‡ºè¯´æ˜ã€‚

### ğŸ’¡ è®°å¿†è¦ç‚¹
- è¦ç‚¹1
- è¦ç‚¹2
"""

    # --- LLM è°ƒç”¨ï¼ˆDeepSeekï¼‰ ---
    async def _call_deepseek(self, prompt: str) -> Optional[str]:
        if self.client is None:
            logger.error("DeepSeek å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ openai å®‰è£…ä¸ API Key é…ç½®ã€‚")
            return None
        try:
            model = self.config.get("model", "deepseek-chat")
            temperature = self.config.get("temperature", 0.6)
            max_tokens = self.config.get("max_tokens", 4096)

            resp = await self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ç»éªŒä¸°å¯Œçš„ä¸­æ–‡æŠ€æœ¯è®²è§£åŠ©æ‰‹ï¼Œæ“…é•¿ç¼–å†™ç»“æ„æ¸…æ™°ã€ä»£ç å¯è¿è¡Œçš„æ•™å­¦ææ–™ã€‚"},
                    {"role": "user", "content": prompt},
                ],
                temperature=temperature,
                max_tokens=max_tokens,
            )
            if resp and resp.choices:
                return resp.choices[0].message.content
            return None
        except Exception as e:
            logger.error(f"DeepSeek API è°ƒç”¨å¤±è´¥: {e}")
            return None

    # --- æŒä¹…åŒ– ---
    def _save_markdown(self, point: KnowledgePoint, content: str) -> None:
        path = self.output_dir / f"{point.id}.md"
        try:
            path.write_text(content, encoding='utf-8')
            rel = path.relative_to(self.base_dir)
            logger.info(f"âœ… å·²ä¿å­˜: {rel}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {path}, åŸå› : {e}")

    # --- å¹¶è¡Œç”Ÿæˆä¸€ä¸ªçŸ¥è¯†ç‚¹ ---
    async def _gen_one(self, point: KnowledgePoint, semaphore: asyncio.Semaphore, force: bool) -> str:
        path = self.output_dir / f"{point.id}.md"
        if not force and path.exists():
            return "skipped"

        async with semaphore:
            prompt = self._build_prompt(point)
            content: Optional[str] = None
            for _ in range(self.config.get("retry_times", 3)):
                content = await self._call_deepseek(prompt)
                if content:
                    break
                await asyncio.sleep(self.config.get("retry_delay", 10))

            if content:
                self._save_markdown(point, content)
                return "success"
            else:
                logger.error(f"âŒ å¤šæ¬¡å°è¯•åä»æœªç”Ÿæˆ: {point.id} ({point.title})")
                return "failed"

    # --- LangGraph èŠ‚ç‚¹å‡½æ•° ---
    async def node_generate_all(self, state: Dict[str, Any]) -> Dict[str, Any]:
        force = bool(state.get("force", False))
        points: List[KnowledgePoint] = state.get("points", [])
        grp_prefixes = state.get("group_prefixes") or self.group_prefix_filter
        if grp_prefixes:
            prefixes = tuple(f"lg-sec-{pref}-" for pref in grp_prefixes)
            points = [p for p in points if p.id.startswith(prefixes)]
        if not points:
            logger.error("çŸ¥è¯†ç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆã€‚")
            return {"results": []}

        max_parallel = int(self.config.get("max_parallel_requests", 8))
        sem = asyncio.Semaphore(max_parallel)

        tasks = [self._gen_one(p, sem, force) for p in points]
        results = await tqdm_asyncio.gather(*tasks, desc="ç”Ÿæˆè¿›åº¦")
        return {"results": results}


def build_graph(generator: LangGraphKnowledgeGeneratorDeepSeek):
    graph = StateGraph(dict)

    def node_load(state: Dict[str, Any]) -> Dict[str, Any]:
        return {"points": generator.knowledge_points, "group_prefixes": state.get("group_prefixes")}

    graph.add_node("load_outline", node_load)
    graph.add_node("generate_all", generator.node_generate_all)

    graph.add_edge(START, "load_outline")
    graph.add_edge("load_outline", "generate_all")
    graph.add_edge("generate_all", END)

    return graph.compile()


def main():
    parser = argparse.ArgumentParser(description="LangGraph å¹¶è¡Œç”Ÿæˆ LangGraph å­¦ä¹ å†…å®¹ï¼ˆDeepSeekï¼‰")
    parser.add_argument("--config", default="config.example.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶")
    parser.add_argument("--max-parallel", type=int, help="è¦†ç›–é…ç½®ä¸­çš„æœ€å¤§å¹¶å‘æ•°")
    parser.add_argument(
        "--group-prefixes",
        type=str,
        help="ä»…ç”ŸæˆæŒ‡å®šå°èŠ‚å‰ç¼€ï¼ˆå¦‚ '3-1'ï¼Œå¯é€—å·åˆ†éš”ï¼‰ã€‚åŒ¹é… id å‰ç¼€ lg-sec-3-1-*",
    )

    args = parser.parse_args()

    gen = LangGraphKnowledgeGeneratorDeepSeek(config_path=args.config)
    if args.max_parallel:
        gen.config["max_parallel_requests"] = args.max_parallel
        logger.info(f"å‘½ä»¤è¡Œè¦†ç›–æœ€å¤§å¹¶å‘æ•°: {args.max_parallel}")

    app = build_graph(gen)

    def _parse_group_prefixes(expr: Optional[str]):
        if not expr:
            return None
        vals = set()
        for tok in [t.strip() for t in expr.split(',') if t.strip()]:
            if re.fullmatch(r"\d+(?:-\d+){1,2}", tok):
                vals.add(tok)
            else:
                logger.warning(f"å¿½ç•¥æ— æ³•è§£æçš„ group å‰ç¼€: {tok}")
        return vals or None

    grp = _parse_group_prefixes(args.group_prefixes)

    initial_state = {"force": bool(args.force), "group_prefixes": grp}

    # å¼‚æ­¥æ‰§è¡Œï¼ˆåŒ…å«å¼‚æ­¥èŠ‚ç‚¹ï¼‰
    asyncio.run(app.ainvoke(initial_state))


if __name__ == "__main__":
    main()
