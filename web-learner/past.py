
#!/usr/bin/env python3
"""
PythonçŸ¥è¯†ç‚¹å†…å®¹æ‰¹é‡ç”Ÿæˆå·¥å…· (å¹¶è¡Œç‰ˆ)
æ ¹æ® python-learning-path.md ä¸­çš„ç»“æ„ï¼Œä½¿ç”¨ asyncio å¹¶è¡Œè°ƒç”¨AI APIç”Ÿæˆæ‰€æœ‰çŸ¥è¯†ç‚¹å†…å®¹ã€‚

å®‰è£…ä¾èµ–:
pip install google-generativeai tqdm
"""

import os
import json
import time
import logging
import re
import asyncio
import argparse
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from pathlib import Path
from datetime import datetime
from tqdm.asyncio import tqdm_asyncio

# --- æ—¥å¿—è®¾ç½® ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('python_generation_parallel_log.txt', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class KnowledgePoint:
    """çŸ¥è¯†ç‚¹æ•°æ®ç»“æ„"""
    id: str
    title: str
    level: int
    chapter: str
    section: str

class KnowledgeGenerator:
    """çŸ¥è¯†ç‚¹å†…å®¹å¹¶è¡Œç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str = "config.example.json"):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.config = self.load_config(config_path)
        self.outline_content, self.knowledge_points = self.load_knowledge_points_from_md('web-learner/public/python-learning-path.md')
        self.output_dir = Path('web-learner/public/content/')
        self.output_dir.mkdir(exist_ok=True)
        
    def load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "api_provider": "gemini",
            "gemini_api_key": os.environ.get("GEMINI_API_KEY", "YOUR_GEMINI_API_KEY_HERE"),
            "model": "gemini-1.5-pro-latest",
            "temperature": 0.6,
            "max_tokens": 4096,
            "retry_times": 3,
            "retry_delay": 10,
            "max_parallel_requests": 8  # æ–°å¢ï¼šæœ€å¤§å¹¶å‘è¯·æ±‚æ•°
        }
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                try:
                    user_config = json.load(f)
                    default_config.update(user_config)
                except json.JSONDecodeError:
                    logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} æ ¼å¼é”™è¯¯ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
        else:
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=2, ensure_ascii=False)
            logger.info(f"å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {config_path}ã€‚è¯·å¡«å…¥ä½ çš„API Keyã€‚")
            
        return default_config

    def load_knowledge_points_from_md(self, md_path: str) -> Tuple[str, List[KnowledgePoint]]:
        """ä»Markdownå¤§çº²æ–‡ä»¶åŠ è½½çŸ¥è¯†ç‚¹"""
        points = []
        content = ""
        try:
            with open(md_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except FileNotFoundError:
            logger.error(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¤§çº²æ–‡ä»¶ {md_path}ã€‚")
            return "", []

        lines = content.split('\n')
        current_chapter = ""
        current_section = ""
        
        for line in lines:
            chapter_match = re.search(r'## ç¬¬(\d+)ç« ï¼š(.+?) \(id: (py-ch-\d+)\)', line)
            if chapter_match:
                current_chapter = chapter_match.group(1)
                continue

            section_match = re.search(r'### ([\d\.]+?) (.+?) \(id: (py-gr-[\d\-]+)\)', line)
            if section_match:
                current_section = section_match.group(1)
                continue

            point_match = re.search(r'#### ([\d\.]+?) (.+?) \(id: (py-sec-[\d\-a-z_]+)\)', line)
            if point_match:
                point_id = point_match.group(3)
                title = point_match.group(2)
                level = line.count('#') - 1
                
                points.append(KnowledgePoint(
                    id=point_id,
                    title=title,
                    level=level,
                    chapter=current_chapter,
                    section=current_section
                ))
        
        logger.info(f"æˆåŠŸä» {md_path} åŠ è½½äº† {len(points)} ä¸ªçŸ¥è¯†ç‚¹ã€‚")
        return content, points

    def generate_prompt(self, point: KnowledgePoint) -> str:
        """ä¸ºå•ä¸ªçŸ¥è¯†ç‚¹ç”Ÿæˆé«˜è´¨é‡çš„prompt"""
        # (æ­¤å‡½æ•°ä¸åŸè„šæœ¬å®Œå…¨ç›¸åŒï¼Œæ­¤å¤„çœç•¥ä»¥ä¿æŒç®€æ´)
        return f"""
ä½ æ˜¯ä¸€åé¡¶çº§çš„Pythonæ•™è‚²ä¸“å®¶ï¼Œæ“…é•¿ä»¥å¾ªåºæ¸è¿›ã€é‡ç‚¹çªå‡ºã€ç”ŸåŠ¨æœ‰è¶£çš„æ–¹å¼è®²è§£å¤æ‚çš„ç¼–ç¨‹æ¦‚å¿µã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä¸ºPythonå­¦ä¹ è·¯å¾„ä¸­çš„ä¸€ä¸ªç‰¹å®šçŸ¥è¯†ç‚¹ç”Ÿæˆè¯¦ç»†çš„æ•™å­¦å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚

**1. å½“å‰çŸ¥è¯†ç‚¹ä¿¡æ¯:**
- **æ ‡é¢˜:** {point.title}
- **ID:** {point.id}

**2. æ•´ä½“å­¦ä¹ å¤§çº²ä¸Šä¸‹æ–‡:**
ä¸ºäº†ç¡®ä¿å†…å®¹ä¸é‡å¤ä¸”æ‰¿ä¸Šå¯ä¸‹ï¼Œè¯·å‚è€ƒä»¥ä¸‹å®Œæ•´çš„Pythonå­¦ä¹ å¤§çº²ã€‚å½“å‰è¦ç”Ÿæˆçš„çŸ¥è¯†ç‚¹æ˜¯ **{point.title}**ã€‚
---
{self.outline_content}
---

**3. å†…å®¹ç”Ÿæˆè¦æ±‚:**
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownç»“æ„ç”Ÿæˆå†…å®¹ï¼Œç¡®ä¿æ¯ä¸ªä»£ç å—éƒ½æ˜¯å®Œæ•´ã€å¯ç‹¬ç«‹è¿è¡Œçš„Pythonä»£ç ã€‚

## {point.title}

### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ
(ç”¨ä¸€å¥è¯è¯´æ˜è¿™ä¸ªçŸ¥è¯†ç‚¹è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œä¸ºä»€ä¹ˆéœ€è¦å®ƒã€‚è¯­è¨€è¦ç²¾ç‚¼ï¼Œç›´å‡»è¦å®³ã€‚)

### ğŸ’¡ ä½¿ç”¨æ–¹å¼
ä»‹ç»è¿™ä¸ªçŸ¥è¯†ç‚¹çš„å…·ä½“ä½¿ç”¨æ–¹å¼

### ğŸ“š Level 1: åŸºç¡€è®¤çŸ¥ï¼ˆ30ç§’ç†è§£ï¼‰
(æä¾›ä¸€ä¸ªæœ€ç®€å•ã€æœ€ç›´è§‚çš„ä»£ç ç¤ºä¾‹ï¼Œè®©åˆå­¦è€…ä¸€çœ¼å°±èƒ½æ˜ç™½åŸºæœ¬ç”¨æ³•ã€‚ä»£ç å¿…é¡»å®Œæ•´å¯è¿è¡Œï¼Œå¹¶ä»¥æ³¨é‡Šçš„å½¢å¼åŒ…å«é¢„æœŸè¾“å‡ºç»“æœã€‚)
```python
# ç¤ºä¾‹ä»£ç 
```

### ğŸ“ˆ Level 2: æ ¸å¿ƒç‰¹æ€§ï¼ˆæ·±å…¥ç†è§£ï¼‰
(å±•ç¤º2-3ä¸ªè¯¥çŸ¥è¯†ç‚¹çš„å…³é”®ç‰¹æ€§æˆ–é«˜çº§ç”¨æ³•ï¼Œæ¯ä¸ªç‰¹æ€§é…ä¸€ä¸ªå®Œæ•´çš„ä»£ç ç¤ºä¾‹å’Œç®€è¦è¯´æ˜ã€‚)

#### ç‰¹æ€§1: [ç‰¹æ€§åç§°]
(ç®€è¦è¯´æ˜)
```python
# ç¤ºä¾‹ä»£ç 
```

#### ç‰¹æ€§2: [ç‰¹æ€§åç§°]
(ç®€è¦è¯´æ˜)
```python
# ç¤ºä¾‹ä»£ç 
```

### ğŸ” Level 3: å¯¹æ¯”å­¦ä¹ ï¼ˆé¿å…é™·é˜±ï¼‰
(é€šè¿‡å¯¹æ¯”â€œé”™è¯¯ç”¨æ³•â€å’Œâ€œæ­£ç¡®ç”¨æ³•â€æ¥å±•ç¤ºå¸¸è§çš„é™·é˜±æˆ–æ˜“æ··æ·†çš„æ¦‚å¿µã€‚æ¯ä¸ªç”¨æ³•éƒ½å¿…é¡»æœ‰å®Œæ•´çš„ä»£ç ç¤ºä¾‹å’Œæ¸…æ™°çš„è§£é‡Šã€‚)

```python
# === é”™è¯¯ç”¨æ³• ===
# âŒ å±•ç¤ºå¸¸è§é”™è¯¯
# è§£é‡Šä¸ºä»€ä¹ˆæ˜¯é”™çš„

# === æ­£ç¡®ç”¨æ³• ===
# âœ… å±•ç¤ºæ­£ç¡®åšæ³•
# è§£é‡Šä¸ºä»€ä¹ˆè¿™æ ·æ˜¯å¯¹çš„
```

### ğŸš€ Level 4: å®æˆ˜åº”ç”¨ï¼ˆçœŸå®åœºæ™¯ï¼‰
(è®¾è®¡ä¸€ä¸ªç”ŸåŠ¨æœ‰è¶£çš„å®æˆ˜åœºæ™¯æ¥ç»¼åˆè¿ç”¨è¯¥çŸ¥è¯†ç‚¹ã€‚åœºæ™¯è¦å¯Œæœ‰åˆ›æ„ï¼Œä¾‹å¦‚æ¸¸æˆã€ç§‘å¹»ã€ç”Ÿæ´»è¶£äº‹ç­‰ï¼Œé¿å…æ¯ç‡¥çš„çº¯ç†è®ºæˆ–å•†ä¸šæ¡ˆä¾‹ã€‚ä»£ç éœ€å®Œæ•´ï¼Œå¹¶æœ‰æ¸…æ™°çš„è¾“å‡ºç»“æœã€‚)

**åœºæ™¯ï¼š** [é€‰æ‹©ä¸€ä¸ªæœ‰è¶£çš„åœºæ™¯ï¼Œå¦‚ï¼šğŸ® æ¸¸æˆè§’è‰²å±æ€§è®¡ç®—å™¨, ğŸš€ æ˜Ÿé™…é£èˆ¹å¯¼èˆªç³»ç»Ÿ, ğŸ• æŠ«è¨è®¢å•å¤„ç†å™¨, ğŸ¾ è™šæ‹Ÿå® ç‰©äº’åŠ¨ç­‰]

```python
# å®æˆ˜åœºæ™¯çš„å®Œæ•´ä»£ç 
```

### ğŸ’¡ è®°å¿†è¦ç‚¹
- **è¦ç‚¹1**: [æ€»ç»“ç¬¬ä¸€ä¸ªå…³é”®è®°å¿†ç‚¹]
- **è¦ç‚¹2**: [æ€»ç»“ç¬¬äºŒä¸ªå…³é”®è®°å¿†ç‚¹]
- **è¦ç‚¹3**: [æ€»ç»“ç¬¬ä¸‰ä¸ªå…³é”®è®°å¿†ç‚¹]

**4. å†…å®¹é£æ ¼è¦æ±‚:**
- **å¾ªåºæ¸è¿›**: ä»æœ€ç®€å•çš„æ¦‚å¿µåˆ°å¤æ‚çš„åº”ç”¨ã€‚
- **é‡ç‚¹çªå‡º**: ä½¿ç”¨åŠ ç²—ã€åˆ—è¡¨ç­‰æ–¹å¼çªå‡ºæ ¸å¿ƒçŸ¥è¯†ã€‚
- **ç”ŸåŠ¨æœ‰è¶£**: Level 4çš„å®æˆ˜åœºæ™¯è¦å¯Œæœ‰æƒ³è±¡åŠ›ï¼Œä½¿ç”¨Emojiå¢åŠ è¶£å‘³æ€§ã€‚
- **ä»£ç å¯è¿è¡Œ**: æ‰€æœ‰ä»£ç å—éƒ½å¿…é¡»æ˜¯ç‹¬ç«‹çš„ã€å®Œæ•´çš„ã€å¯ä»¥ç›´æ¥å¤åˆ¶è¿è¡Œçš„ã€‚
- **ä¸­æ–‡è®²è§£**: æ‰€æœ‰è§£é‡Šå’Œæ³¨é‡Šéƒ½ä½¿ç”¨ä¸­æ–‡ã€‚

è¯·ç°åœ¨å¼€å§‹ä¸ºçŸ¥è¯†ç‚¹ **"{point.title}"** ç”Ÿæˆå†…å®¹ã€‚
"""

    async def call_gemini_api_async(self, prompt: str) -> Optional[str]:
        """å¼‚æ­¥è°ƒç”¨Google Gemini API"""
        try:
            import google.generativeai as genai
        except ImportError:
            logger.error("Google GenerativeAIåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
            return None

        try:
            api_key = self.config.get("gemini_api_key")
            if not api_key or "YOUR_GEMINI_API_KEY_HERE" in api_key:
                logger.error("Gemini API Key æœªåœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ã€‚")
                return None
            
            genai.configure(api_key=api_key)
            
            model = genai.GenerativeModel(
                model_name=self.config.get("model", "gemini-1.5-pro-latest"),
                generation_config={
                    "temperature": self.config.get("temperature", 0.6),
                    "max_output_tokens": self.config.get("max_tokens", 4096),
                }
            )
            
            response = await model.generate_content_async(prompt)
            return response.text
        except Exception as e:
            logger.error(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def save_content(self, point: KnowledgePoint, content: str):
        """ä¿å­˜ç”Ÿæˆçš„å†…å®¹åˆ°æ–‡ä»¶"""
        filename = f"{point.id}.md"
        filepath = self.output_dir / filename
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            logger.info(f"âœ… å·²ä¿å­˜: {filepath.name}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {filepath.name}, åŸå› : {e}")

    async def generate_one_point_async(self, point: KnowledgePoint, semaphore: asyncio.Semaphore, force_regenerate: bool) -> str:
        """å¤„ç†å•ä¸ªçŸ¥è¯†ç‚¹çš„ç”Ÿæˆ (å¼‚æ­¥å·¥ä½œå•å…ƒ)"""
        filepath = self.output_dir / f"{point.id}.md"
        if not force_regenerate and filepath.exists():
            logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {point.title}")
            return "skipped"

        async with semaphore:
            logger.info(f"--- å¼€å§‹å¤„ç†: {point.title} ---")
            prompt = self.generate_prompt(point)
            
            content = None
            for attempt in range(self.config.get("retry_times", 3)):
                content = await self.call_gemini_api_async(prompt)
                if content:
                    break
                logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥ ({point.title})ï¼Œå°†åœ¨ {self.config.get('retry_delay', 10)} ç§’åé‡è¯•...")
                await asyncio.sleep(self.config.get('retry_delay', 10))

            if content:
                self.save_content(point, content)
                return "success"
            else:
                logger.error(f"âŒ ç»è¿‡å¤šæ¬¡å°è¯•ï¼Œç”Ÿæˆ {point.id} ({point.title}) å¤±è´¥ã€‚")
                return "failed"

    async def run_parallel_generation(self, force_regenerate: bool):
        """ä¸»ç”Ÿæˆæµç¨‹ (å¹¶è¡Œç‰ˆ)"""
        if not self.knowledge_points:
            logger.error("çŸ¥è¯†ç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç”Ÿæˆã€‚")
            return

        max_parallel = self.config.get("max_parallel_requests", 8)
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(self.knowledge_points)} ä¸ªPythonçŸ¥è¯†ç‚¹å†…å®¹ (æœ€å¤§å¹¶å‘æ•°: {max_parallel})...")
        
        semaphore = asyncio.Semaphore(max_parallel)
        
        tasks = [
            self.generate_one_point_async(point, semaphore, force_regenerate)
            for point in self.knowledge_points
        ]
        
        results = await tqdm_asyncio.gather(*tasks, desc="ç”Ÿæˆè¿›åº¦")

        # ç»Ÿè®¡ç»“æœ
        success_count = results.count("success")
        skipped_count = results.count("skipped")
        failed_count = results.count("failed")

        logger.info("ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ï¼ ğŸ‰ğŸ‰ğŸ‰")
        logger.info(f"ç»Ÿè®¡: æˆåŠŸ {success_count}, è·³è¿‡ {skipped_count}, å¤±è´¥ {failed_count}")


def main():
    """ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="PythonçŸ¥è¯†ç‚¹å†…å®¹æ‰¹é‡ç”Ÿæˆå·¥å…· (å¹¶è¡Œç‰ˆ)")
    parser.add_argument("--config", default="config.example.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ‰€æœ‰æ–‡ä»¶ï¼Œå³ä½¿å®ƒä»¬å·²å­˜åœ¨")
    parser.add_argument("--max-parallel", type=int, help="è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„æœ€å¤§å¹¶å‘æ•°")
    
    args = parser.parse_args()
    
    generator = KnowledgeGenerator(config_path=args.config)

    if args.max_parallel:
        generator.config["max_parallel_requests"] = args.max_parallel
        logger.info(f"å‘½ä»¤è¡Œè¦†ç›–æœ€å¤§å¹¶å‘æ•°: {args.max_parallel}")

    asyncio.run(generator.run_parallel_generation(force_regenerate=args.force))

if __name__ == "__main__":
    main()