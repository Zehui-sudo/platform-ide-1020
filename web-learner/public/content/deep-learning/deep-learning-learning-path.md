# 深度学习 (id: deep-learning)

## 第1章：模块一：神经网络的基石 (The Cornerstone of Neural Networks) (id: dl-mod-1)
### 模块一：神经网络的基石 (The Cornerstone of Neural Networks) (id: dl-mod-1-gr-1)
#### 1.1 根本问题：如何让机器从数据中自动学习模式？ (id: dl-sec-1-1)
#### 1.2 核心思想：从线性模型到多层感知机(MLP) (id: dl-sec-1-2)
#### 1.3 拆解关键机制：训练循环、反向传播与梯度下降 (id: dl-sec-1-3)

## 第2章：模块二：深度网络训练手册 (A Handbook for Training Deep Networks) (id: dl-mod-2)
### 模块二：深度网络训练手册 (A Handbook for Training Deep Networks) (id: dl-mod-2-gr-1)
#### 2.1 根本问题：为什么深度网络难以训练？ (id: dl-sec-2-1)
#### 2.2 优化器工具箱：更快更好地找到最小值 (id: dl-sec-2-2)
#### 2.3 正则化工具箱：防止模型“死记硬背” (id: dl-sec-2-3)
#### 2.4 初始化与归一化工具箱：让训练更稳定 (id: dl-sec-2-4)

## 第3章：模块三：洞察空间 - 卷积神经网络(CNN) (id: dl-mod-3)
### 模块三：洞察空间 - 卷积神经网络(CNN) (id: dl-mod-3-gr-1)
#### 3.1 根本问题：如何高效处理图像等网格数据？ (id: dl-sec-3-1)
#### 3.2 核心思想与机制：卷积层与池化层 (id: dl-sec-3-2)
#### 3.3 架构演进：从LeNet到ResNet (id: dl-sec-3-3)
#### 3.4 典型应用：图像分类与目标检测简介 (id: dl-sec-3-4)

## 第4章：模块四：理解序列 - 从RNN到Transformer (id: dl-mod-4)
### 模块四：理解序列 - 从RNN到Transformer (id: dl-mod-4-gr-1)
#### 4.1 根本问题：如何处理长度可变、顺序攸关的数据？ (id: dl-sec-4-1)
#### 4.2 解决方案1.0：循环神经网络 (RNN) 与长短期记忆 (LSTM) (id: dl-sec-4-2)
#### 4.3 解决方案2.0：编码器-解码器 (Seq2Seq) 与注意力机制 (Attention) (id: dl-sec-4-3)
#### 4.4 解决方案3.0：Transformer - 注意力就是你所需要的一切 (id: dl-sec-4-4)

## 第5章：模块五：现代范式 - 预训练、微调与大模型 (id: dl-mod-5)
### 模块五：现代范式 - 预训练、微调与大模型 (id: dl-mod-5-gr-1)
#### 5.1 根本问题：如何有效利用海量的无标签文本数据？ (id: dl-sec-5-1)
#### 5.2 阶段一：静态词向量 (Word2Vec) (id: dl-sec-5-2)
#### 5.3 阶段二：上下文表示与BERT (id: dl-sec-5-3)
#### 5.4 实践指南：预训练-微调工作流 (id: dl-sec-5-4)

## 第6章：模块六：创造新世界 - 生成式模型入门 (id: dl-mod-6)
### 模块六：创造新世界 - 生成式模型入门 (id: dl-mod-6-gr-1)
#### 6.1 根本问题：如何让模型学习数据的内在分布并创造新样本？ (id: dl-sec-6-1)
#### 6.2 工具一：变分自编码器 (VAE) (id: dl-sec-6-2)
#### 6.3 工具二：生成对抗网络 (GAN) (id: dl-sec-6-3)
#### 6.4 工具三：扩散模型 (Diffusion Models) 简介 (id: dl-sec-6-4)
