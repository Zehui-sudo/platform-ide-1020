```markdown
# å®šä¹‰ StateGraph

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ
StateGraph æ˜¯ LangGraph ä¸­æ„å»ºæœ‰çŠ¶æ€å·¥ä½œæµçš„æ ¸å¿ƒéª¨æ¶ï¼Œå®ƒé€šè¿‡ç»Ÿä¸€çš„çŠ¶æ€ç®¡ç†æœºåˆ¶è§£å†³äº†å¤šæ­¥éª¤ Agent æµç¨‹ä¸­çš„çŠ¶æ€ä¼ é€’å’Œå…±äº«é—®é¢˜ï¼Œæ˜¯æ„å»ºå¤æ‚ AI åº”ç”¨çš„å…³é”®åŸºç¡€ã€‚

## ğŸ’¡ ä½¿ç”¨æ–¹å¼
StateGraph çš„æ ¸å¿ƒ API æ˜¯é€šè¿‡ `StateGraph` ç±»æ¥åˆ›å»ºå›¾å®ä¾‹ï¼Œéœ€è¦æŒ‡å®šçŠ¶æ€ Schema æ¥å®šä¹‰å·¥ä½œæµä¸­ä¼ é€’çš„æ•°æ®ç»“æ„ã€‚

```python
from langgraph.graph import StateGraph
from typing import TypedDict

# å®šä¹‰çŠ¶æ€ç»“æ„
class AgentState(TypedDict):
    input: str
    processed_data: str

# åˆ›å»º StateGraph å®ä¾‹
graph = StateGraph(AgentState)
```

## ğŸ“š Level 1: åŸºç¡€è®¤çŸ¥ï¼ˆ30ç§’ç†è§£ï¼‰
æœ€åŸºæœ¬çš„ StateGraph å®šä¹‰å’Œè¿è¡Œç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªæœ€å°å¯å·¥ä½œçš„å·¥ä½œæµã€‚

```python
from langgraph.graph import StateGraph
from typing import TypedDict

# 1. å®šä¹‰çŠ¶æ€ç»“æ„
class SimpleState(TypedDict):
    message: str

# 2. å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def start_node(state: SimpleState):
    return {"message": "Hello from StateGraph!"}

# 3. åˆ›å»ºå¹¶é…ç½®å›¾
graph = StateGraph(SimpleState)
graph.add_node("start", start_node)
graph.set_entry_point("start")
graph.set_finish_point("start")

# 4. ç¼–è¯‘å¹¶è¿è¡Œ
app = graph.compile()
result = app.invoke({"message": ""})
print(result["message"])  # è¾“å‡º: Hello from StateGraph!
```

## ğŸ“ˆ Level 2: æ ¸å¿ƒç‰¹æ€§ï¼ˆæ·±å…¥ç†è§£ï¼‰

### ç‰¹æ€§1: çŠ¶æ€æ›´æ–°ä¸ä¼ é€’
StateGraph çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯çŠ¶æ€åœ¨å„ä¸ªèŠ‚ç‚¹é—´çš„è‡ªåŠ¨ä¼ é€’å’Œæ›´æ–°ã€‚

```python
from langgraph.graph import StateGraph
from typing import TypedDict

class ProcessingState(TypedDict):
    input_text: str
    processed_text: str
    step_count: int

def preprocess_node(state: ProcessingState):
    # å¤„ç†è¾“å…¥æ–‡æœ¬
    processed = state["input_text"].upper()
    return {"processed_text": processed, "step_count": 1}

def count_node(state: ProcessingState):
    # ç»Ÿè®¡å­—ç¬¦æ•°
    char_count = len(state["processed_text"])
    return {"processed_text": f"{state['processed_text']} ({char_count} chars)", 
            "step_count": state["step_count"] + 1}

# æ„å»ºå·¥ä½œæµ
graph = StateGraph(ProcessingState)
graph.add_node("preprocess", preprocess_node)
graph.add_node("count", count_node)

graph.set_entry_point("preprocess")
graph.add_edge("preprocess", "count")
graph.set_finish_point("count")

app = graph.compile()
result = app.invoke({"input_text": "hello world", "processed_text": "", "step_count": 0})
print(result)  # è¾“å‡ºå¤„ç†åçš„çŠ¶æ€
```

### ç‰¹æ€§2: æ¡ä»¶è¾¹ä¸åŠ¨æ€æµç¨‹
StateGraph æ”¯æŒåŸºäºçŠ¶æ€çš„æ¡ä»¶åˆ†æ”¯ï¼Œå®ç°åŠ¨æ€å·¥ä½œæµã€‚

```python
from langgraph.graph import StateGraph
from typing import TypedDict, Literal

class RoutingState(TypedDict):
    input_type: Literal["text", "number", "other"]
    data: str
    result: str

def classify_node(state: RoutingState):
    if state["data"].isdigit():
        return {"input_type": "number"}
    elif state["data"].isalpha():
        return {"input_type": "text"}
    else:
        return {"input_type": "other"}

def process_text(state: RoutingState):
    return {"result": f"Text processed: {state['data'].upper()}"}

def process_number(state: RoutingState):
    return {"result": f"Number squared: {int(state['data'])**2}"}

def process_other(state: RoutingState):
    return {"result": f"Other input: {state['data']}"}

graph = StateGraph(RoutingState)
graph.add_node("classify", classify_node)
graph.add_node("process_text", process_text)
graph.add_node("process_number", process_number)
graph.add_node("process_other", process_other)

graph.set_entry_point("classify")

# æ·»åŠ æ¡ä»¶è¾¹
graph.add_conditional_edges(
    "classify",
    lambda state: state["input_type"],
    {
        "text": "process_text",
        "number": "process_number", 
        "other": "process_other"
    }
)

graph.set_finish_point("process_text")
graph.set_finish_point("process_number")
graph.set_finish_point("process_other")

app = graph.compile()

# æµ‹è¯•ä¸åŒç±»å‹è¾“å…¥
print(app.invoke({"data": "hello", "input_type": "", "result": ""}))
print(app.invoke({"data": "42", "input_type": "", "result": ""}))
print(app.invoke({"data": "hello123", "input_type": "", "result": ""}))
```

## ğŸ” Level 3: å¯¹æ¯”å­¦ä¹ ï¼ˆé¿å…é™·é˜±ï¼‰

### çŠ¶æ€æ›´æ–°æ–¹å¼å¯¹æ¯”
é”™è¯¯ç”¨æ³•ï¼šç›´æ¥ä¿®æ”¹çŠ¶æ€å¯¹è±¡ vs æ­£ç¡®ç”¨æ³•ï¼šè¿”å›æ›´æ–°å­—å…¸

```python
# âŒ é”™è¯¯ç”¨æ³•ï¼šç›´æ¥ä¿®æ”¹çŠ¶æ€ï¼ˆä¸ä¼šç”Ÿæ•ˆï¼‰
def wrong_node(state):
    state["value"] = "modified"  # è¿™ä¸ä¼šæ›´æ–°çŠ¶æ€
    return state

# âœ… æ­£ç¡®ç”¨æ³•ï¼šè¿”å›æ›´æ–°å­—å…¸
def correct_node(state):
    return {"value": "modified"}  # è¿”å›è¦æ›´æ–°çš„å­—æ®µ

# éªŒè¯å·®å¼‚
from langgraph.graph import StateGraph
from typing import TypedDict

class TestState(TypedDict):
    value: str

graph = StateGraph(TestState)
graph.add_node("test", correct_node)  # æ”¹ä¸º wrong_node æµ‹è¯•é”™è¯¯æƒ…å†µ
graph.set_entry_point("test")
graph.set_finish_point("test")

app = graph.compile()
result = app.invoke({"value": "original"})
print(result["value"])  # æ­£ç¡®è¾“å‡º: modified
```

## ğŸš€ Level 4: å®æˆ˜åº”ç”¨ï¼ˆçœŸå®åœºæ™¯ï¼‰
æ„å»ºä¸€ä¸ªç®€å•çš„æ–‡æ¡£å¤„ç†æµæ°´çº¿ï¼ŒåŒ…å«æ–‡æœ¬æ¸…ç†ã€å…³é”®è¯æå–å’Œæ‘˜è¦ç”Ÿæˆã€‚

```python
from langgraph.graph import StateGraph
from typing import TypedDict, List
import re

class DocumentState(TypedDict):
    raw_text: str
    cleaned_text: str
    keywords: List[str]
    summary: str

def clean_text_node(state: DocumentState):
    # ç®€å•çš„æ–‡æœ¬æ¸…ç†
    cleaned = re.sub(r'\s+', ' ', state["raw_text"]).strip()
    return {"cleaned_text": cleaned}

def extract_keywords_node(state: DocumentState):
    # æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰
    words = state["cleaned_text"].split()
    keywords = [word for word in words if len(word) > 5][:3]  # å–é•¿åº¦å¤§äº5çš„å‰3ä¸ªè¯
    return {"keywords": keywords}

def generate_summary_node(state: DocumentState):
    # ç”Ÿæˆç®€å•æ‘˜è¦
    sentences = state["cleaned_text"].split('. ')
    summary = '. '.join(sentences[:2]) + '.'  # å–å‰ä¸¤å¥ä½œä¸ºæ‘˜è¦
    return {"summary": summary}

# æ„å»ºæ–‡æ¡£å¤„ç†æµæ°´çº¿
graph = StateGraph(DocumentState)
graph.add_node("clean", clean_text_node)
graph.add_node("extract_keywords", extract_keywords_node)
graph.add_node("generate_summary", generate_summary_node)

graph.set_entry_point("clean")
graph.add_edge("clean", "extract_keywords")
graph.add_edge("extract_keywords", "generate_summary")
graph.set_finish_point("generate_summary")

app = graph.compile()

# å¤„ç†ç¤ºä¾‹æ–‡æ¡£
document = """
LangGraph is a powerful library for building stateful, multi-step AI applications. 
It provides a clean abstraction for managing complex workflows with memory and state. 
The library is particularly useful for building agentic systems that require 
sequential processing and conditional logic. With its intuitive API, developers 
can quickly create sophisticated AI pipelines.
"""

result = app.invoke({
    "raw_text": document,
    "cleaned_text": "",
    "keywords": [],
    "summary": ""
})

print("Cleaned Text:", result["cleaned_text"])
print("Keywords:", result["keywords"])
print("Summary:", result["summary"])
```

## ğŸ’¡ è®°å¿†è¦ç‚¹
- StateGraph æ˜¯æ„å»ºæœ‰çŠ¶æ€å·¥ä½œæµçš„éª¨æ¶ï¼Œéœ€è¦æ˜ç¡®å®šä¹‰çŠ¶æ€ç»“æ„
- èŠ‚ç‚¹å‡½æ•°é€šè¿‡è¿”å›å­—å…¸æ¥æ›´æ–°çŠ¶æ€ï¼Œè€Œä¸æ˜¯ç›´æ¥ä¿®æ”¹è¾“å…¥çŠ¶æ€
- çŠ¶æ€åœ¨èŠ‚ç‚¹é—´è‡ªåŠ¨ä¼ é€’ï¼Œç¡®ä¿å·¥ä½œæµçš„è¿è´¯æ€§
- æ¡ä»¶è¾¹å…è®¸åŸºäºçŠ¶æ€å€¼å®ç°åŠ¨æ€åˆ†æ”¯é€»è¾‘
- åˆç†çš„çŠ¶æ€è®¾è®¡æ˜¯æ„å»ºå¤æ‚ Agent ç³»ç»Ÿçš„å…³é”®åŸºç¡€
```