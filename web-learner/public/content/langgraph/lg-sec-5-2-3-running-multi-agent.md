```markdown
# è¿è¡Œå®Œæ•´çš„å¤šAgentåä½œæµç¨‹

### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ
è¿è¡Œå®Œæ•´çš„å¤šAgentåä½œæµç¨‹æ˜¯æ„å»ºå¤æ‚AIç³»ç»Ÿçš„å…³é”®ï¼Œå®ƒè§£å†³äº†å•ä¸ªAgentèƒ½åŠ›æœ‰é™çš„é—®é¢˜ï¼Œé€šè¿‡å¤šä¸ªä¸“ä¸šåŒ–Agentçš„ååŒå·¥ä½œï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡å¹¶äº§ç”Ÿæ›´ä¼˜è´¨çš„ç»“æœã€‚

### ğŸ’¡ ä½¿ç”¨æ–¹å¼
æ ¸å¿ƒAPIæ˜¯`app.stream()`æˆ–`app.invoke()`ï¼Œç”¨äºæ‰§è¡Œæ„å»ºå¥½çš„å¤šAgentå›¾ã€‚é€šè¿‡å®šä¹‰æ¸…æ™°çš„çŠ¶æ€æµè½¬è§„åˆ™å’ŒAgentåˆ†å·¥ï¼Œå®ç°é«˜æ•ˆçš„åä½œæµç¨‹ã€‚

### ğŸ“š Level 1: åŸºç¡€è®¤çŸ¥ï¼ˆ30ç§’ç†è§£ï¼‰
ä¸€ä¸ªæœ€ç®€å•çš„å¤šAgentåä½œæµç¨‹ï¼ŒåŒ…å«ç ”ç©¶å‘˜å’Œå†™ä½œå‘˜ä¸¤ä¸ªAgentçš„ååŒå·¥ä½œã€‚

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict
from langchain_openai import ChatOpenAI

# å®šä¹‰å…±äº«çŠ¶æ€
class ResearchState(TypedDict):
    topic: str
    research_data: str
    final_report: str

# åˆå§‹åŒ–æ¨¡å‹
llm = ChatOpenAI(model="gpt-3.5-turbo")

# å®šä¹‰ç ”ç©¶å‘˜Agent
def research_agent(state: ResearchState):
    prompt = f"è¯·ç ”ç©¶ä»¥ä¸‹ä¸»é¢˜å¹¶æä¾›è¯¦ç»†èµ„æ–™: {state['topic']}"
    response = llm.invoke(prompt)
    return {"research_data": response.content}

# å®šä¹‰å†™ä½œå‘˜Agent
def writer_agent(state: ResearchState):
    prompt = f"æ ¹æ®ä»¥ä¸‹ç ”ç©¶èµ„æ–™æ’°å†™æŠ¥å‘Š:\n{state['research_data']}\n\nä¸»é¢˜: {state['topic']}"
    response = llm.invoke(prompt)
    return {"final_report": response.content}

# æ„å»ºå›¾
builder = StateGraph(ResearchState)
builder.add_node("researcher", research_agent)
builder.add_node("writer", writer_agent)

# è®¾ç½®æµç¨‹
builder.set_entry_point("researcher")
builder.add_edge("researcher", "writer")
builder.add_edge("writer", END)

# ç¼–è¯‘å›¾
app = builder.compile()

# è¿è¡Œå®Œæ•´æµç¨‹
result = app.invoke({"topic": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"})
print("æœ€ç»ˆæŠ¥å‘Š:", result["final_report"])
```

### ğŸ“ˆ Level 2: æ ¸å¿ƒç‰¹æ€§ï¼ˆæ·±å…¥ç†è§£ï¼‰

#### ç‰¹æ€§1: æ¡ä»¶è·¯ç”±ä¸åŠ¨æ€å†³ç­–
å®ç°åŸºäºå†…å®¹è´¨é‡çš„æ¡ä»¶è·¯ç”±ï¼Œè®©Supervisor Agentå†³å®šæ˜¯å¦éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ã€‚

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Literal
from langchain_openai import ChatOpenAI
import json

class ResearchState(TypedDict):
    topic: str
    research_data: str
    final_report: str
    quality_check: Literal["pass", "need_more_research"]

llm = ChatOpenAI(model="gpt-3.5-turbo")

def research_agent(state: ResearchState):
    prompt = f"æ·±å…¥ç ”ç©¶: {state['topic']}"
    response = llm.invoke(prompt)
    return {"research_data": response.content}

def writer_agent(state: ResearchState):
    prompt = f"æ’°å†™æŠ¥å‘Š: {state['research_data']}"
    response = llm.invoke(prompt)
    return {"final_report": response.content}

def quality_checker(state: ResearchState):
    prompt = f"""è¯„ä¼°ä»¥ä¸‹ç ”ç©¶èµ„æ–™çš„è´¨é‡ï¼Œå¦‚æœèµ„æ–™å……åˆ†ä¸”ç›¸å…³è¿”å›passï¼Œå¦åˆ™è¿”å›need_more_research:
    
    ä¸»é¢˜: {state['topic']}
    ç ”ç©¶èµ„æ–™: {state['research_data']}
    
    åªè¿”å›JSON: {{"decision": "pass"}} æˆ– {{"decision": "need_more_research"}}"""
    
    response = llm.invoke(prompt)
    decision = json.loads(response.content)["decision"]
    return {"quality_check": decision}

def should_continue(state: ResearchState):
    if state["quality_check"] == "pass":
        return "writer"
    return "researcher"

# æ„å»ºå›¾
builder = StateGraph(ResearchState)
builder.add_node("researcher", research_agent)
builder.add_node("quality_check", quality_checker)
builder.add_node("writer", writer_agent)

builder.set_entry_point("researcher")
builder.add_edge("researcher", "quality_check")
builder.add_conditional_edges("quality_check", should_continue, ["researcher", "writer"])
builder.add_edge("writer", END)

app = builder.compile()

# è¿è¡Œå¸¦æ¡ä»¶æ£€æŸ¥çš„æµç¨‹
result = app.invoke({"topic": "é‡å­è®¡ç®—çš„æœ€æ–°è¿›å±•"})
print("æœ€ç»ˆæŠ¥å‘Š:", result["final_report"])
```

### ğŸ” Level 3: å¯¹æ¯”å­¦ä¹ ï¼ˆé¿å…é™·é˜±ï¼‰

#### çŠ¶æ€å…±äº«çš„æ­£ç¡®æ–¹å¼
é”™è¯¯æ–¹å¼ï¼šç›´æ¥ä¿®æ”¹å…¨å±€çŠ¶æ€ï¼›æ­£ç¡®æ–¹å¼ï¼šé€šè¿‡è¿”å›å­—å…¸æ›´æ–°çŠ¶æ€

```python
# é”™è¯¯ç”¨æ³•ï¼šç›´æ¥ä¿®æ”¹ä¼ å…¥çš„çŠ¶æ€å¯¹è±¡
def bad_research_agent(state: ResearchState):
    # é”™è¯¯ï¼šç›´æ¥ä¿®æ”¹ä¼ å…¥çš„çŠ¶æ€
    state["research_data"] = "ä¸€äº›æ•°æ®"  # è¿™ä¸ä¼šæ­£ç¡®æ›´æ–°çŠ¶æ€
    return state

# æ­£ç¡®ç”¨æ³•ï¼šè¿”å›è¦æ›´æ–°çš„å­—æ®µå­—å…¸
def good_research_agent(state: ResearchState):
    # æ­£ç¡®ï¼šè¿”å›è¦æ›´æ–°çš„å­—æ®µ
    return {"research_data": "ä¸€äº›æ•°æ®"}
```

### ğŸš€ Level 4: å®æˆ˜åº”ç”¨ï¼ˆçœŸå®åœºæ™¯ï¼‰
æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç ”ç©¶å›¢é˜Ÿï¼ŒåŒ…å«é¢†åŸŸä¸“å®¶ã€æ•°æ®åˆ†æå¸ˆå’ŒæŠ¥å‘Šæ’°å†™å‘˜ã€‚

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict
from langchain_openai import ChatOpenAI
import asyncio

class ResearchTeamState(TypedDict):
    topic: str
    expert_analysis: str
    data_analysis: str
    final_report: str

llm = ChatOpenAI(model="gpt-3.5-turbo")

async def expert_analyst(state: ResearchTeamState):
    prompt = f"ä½œä¸ºé¢†åŸŸä¸“å®¶ï¼Œè¯·åˆ†æ: {state['topic']}"
    response = await llm.ainvoke(prompt)
    return {"expert_analysis": response.content}

async def data_analyst(state: ResearchTeamState):
    prompt = f"ä½œä¸ºæ•°æ®åˆ†æå¸ˆï¼Œè¯·æä¾›æ•°æ®è§†è§’: {state['topic']}"
    response = await llm.ainvoke(prompt)
    return {"data_analysis": response.content}

async def report_writer(state: ResearchTeamState):
    prompt = f"""ç»¼åˆä»¥ä¸‹ä¿¡æ¯æ’°å†™ä¸“ä¸šæŠ¥å‘Š:
    
    ä¸“å®¶åˆ†æ: {state['expert_analysis']}
    æ•°æ®åˆ†æ: {state['data_analysis']}
    
    ä¸»é¢˜: {state['topic']}"""
    
    response = await llm.ainvoke(prompt)
    return {"final_report": response.content}

# æ„å»ºå¹¶è¡Œæ‰§è¡Œçš„ç ”ç©¶å›¢é˜Ÿ
builder = StateGraph(ResearchTeamState)

# æ·»åŠ å¹¶è¡Œæ‰§è¡Œçš„ä¸“å®¶èŠ‚ç‚¹
builder.add_node("expert", expert_analyst)
builder.add_node("analyst", data_analyst)
builder.add_node("writer", report_writer)

# è®¾ç½®å¹¶è¡Œæ‰§è¡Œè·¯å¾„
builder.set_entry_point("expert")
builder.set_entry_point("analyst")

# ç­‰å¾…ä¸¤ä¸ªä¸“å®¶å®Œæˆåå†è¿›å…¥å†™ä½œé˜¶æ®µ
builder.add_edge("expert", "writer")
builder.add_edge("analyst", "writer")
builder.add_edge("writer", END)

app = builder.compile()

# è¿è¡Œå®Œæ•´çš„ç ”ç©¶å›¢é˜Ÿ
async def run_research_team():
    result = await app.ainvoke({"topic": "å¯å†ç”Ÿèƒ½æºçš„æœªæ¥å‘å±•è¶‹åŠ¿"})
    print("ç ”ç©¶å›¢é˜Ÿæœ€ç»ˆæŠ¥å‘Š:")
    print(result["final_report"])

# æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
asyncio.run(run_research_team())
```

### ğŸ’¡ è®°å¿†è¦ç‚¹
- å¤šAgentåä½œé€šè¿‡ä¸“ä¸šåŒ–åˆ†å·¥æå‡æ•´ä½“ä»»åŠ¡å¤„ç†èƒ½åŠ›
- çŠ¶æ€ç®¡ç†æ˜¯Agenté—´é€šä¿¡çš„å…³é”®ï¼Œå¿…é¡»é€šè¿‡è¿”å›å­—å…¸æ­£ç¡®æ›´æ–°
- æ¡ä»¶è·¯ç”±å…è®¸æ ¹æ®ä¸­é—´ç»“æœåŠ¨æ€è°ƒæ•´å·¥ä½œæµç¨‹
- å¹¶è¡Œæ‰§è¡Œå¯ä»¥æ˜¾è‘—æé«˜å¤šAgentç³»ç»Ÿçš„æ•ˆç‡
- æ¸…æ™°çš„Agentè§’è‰²å®šä¹‰å’Œæ¥å£è®¾è®¡æ˜¯æˆåŠŸåä½œçš„åŸºç¡€
```