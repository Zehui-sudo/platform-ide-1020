# ç¼–è¯‘ä¸è¿è¡Œ (compile, stream)

### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ
ç¼–è¯‘ä¸è¿è¡Œæ˜¯å°†æ„å»ºå¥½çš„ LangGraph å›¾è½¬æ¢ä¸ºå¯æ‰§è¡Œå¯¹è±¡å¹¶å¯åŠ¨å·¥ä½œæµçš„å…³é”®æ­¥éª¤ï¼Œå®ƒä½¿å¾—é™æ€çš„å›¾å®šä¹‰èƒ½å¤Ÿå¤„ç†åŠ¨æ€çš„è¾“å…¥æ•°æ®ï¼Œæ˜¯æ„å»ºå¤æ‚ Agent æµç¨‹çš„åŸºç¡€ã€‚

### ğŸ’¡ ä½¿ç”¨æ–¹å¼
LangGraph æä¾›äº†ä¸¤ç§ä¸»è¦çš„æ‰§è¡Œæ–¹å¼ï¼š
- `compile()`: å°†å›¾ç¼–è¯‘ä¸ºå¯æ‰§è¡Œå¯¹è±¡
- `stream()`: ä»¥æµå¼æ–¹å¼æ‰§è¡Œå›¾ï¼Œå¯å®æ—¶è§‚å¯Ÿæ‰§è¡Œè¿‡ç¨‹

```python
# åŸºæœ¬ç”¨æ³•
compiled_graph = graph.compile()
result = compiled_graph.invoke(input_state)

# æµå¼æ‰§è¡Œ
for step in graph.stream(input_state):
    print(step)
```

### ğŸ“š Level 1: åŸºç¡€è®¤çŸ¥ï¼ˆ30ç§’ç†è§£ï¼‰
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

# å®šä¹‰çŠ¶æ€
class State(TypedDict):
    message: str

# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def process_message(state: State) -> State:
    return {"message": f"Processed: {state['message']}"}

# æ„å»ºå›¾
graph = StateGraph(State)
graph.add_node("processor", process_message)
graph.set_entry_point("processor")
graph.set_finish_point("processor")

# ç¼–è¯‘å›¾
compiled_graph = graph.compile()

# è¿è¡Œå›¾
input_state = {"message": "Hello LangGraph!"}
result = compiled_graph.invoke(input_state)
print(result["message"])  # è¾“å‡º: Processed: Hello LangGraph!
```

### ğŸ“ˆ Level 2: æ ¸å¿ƒç‰¹æ€§ï¼ˆæ·±å…¥ç†è§£ï¼‰

#### ç‰¹æ€§1: æµå¼æ‰§è¡Œä¸å®æ—¶ç›‘æ§
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict
import time

class State(TypedDict):
    message: str
    steps: int

def step1(state: State) -> State:
    time.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    return {"message": state["message"] + " â†’ Step1", "steps": state["steps"] + 1}

def step2(state: State) -> State:
    time.sleep(0.5)
    return {"message": state["message"] + " â†’ Step2", "steps": state["steps"] + 1}

# æ„å»ºå›¾
graph = StateGraph(State)
graph.add_node("step1", step1)
graph.add_node("step2", step2)
graph.add_edge("step1", "step2")
graph.add_edge("step2", END)
graph.set_entry_point("step1")

# æµå¼æ‰§è¡Œï¼Œå®æ—¶è§‚å¯Ÿæ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡º
input_state = {"message": "Start", "steps": 0}
print("æµå¼æ‰§è¡Œè¿‡ç¨‹:")
for step_name, step_output in graph.stream(input_state):
    print(f"èŠ‚ç‚¹ {step_name}: {step_output}")

print("\næœ€ç»ˆç»“æœ:")
result = graph.compile().invoke(input_state)
print(result)
```

#### ç‰¹æ€§2: æ‰¹é‡å¤„ç†ä¸é…ç½®å‚æ•°
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, List

class State(TypedDict):
    messages: List[str]
    processed_count: int

def process_batch(state: State) -> State:
    processed = [f"PROCESSED: {msg}" for msg in state["messages"]]
    return {
        "messages": processed,
        "processed_count": state["processed_count"] + len(processed)
    }

graph = StateGraph(State)
graph.add_node("batch_processor", process_batch)
graph.set_entry_point("batch_processor")
graph.set_finish_point("batch_processor")

compiled_graph = graph.compile()

# æ‰¹é‡å¤„ç†
batch_input = {
    "messages": ["Hello", "World", "LangGraph"],
    "processed_count": 0
}

# ä½¿ç”¨é…ç½®å‚æ•°ï¼ˆè¿™é‡Œæ¼”ç¤ºé…ç½®ä¼ é€’ï¼Œè™½ç„¶è¿™ä¸ªç®€å•ä¾‹å­ä¸éœ€è¦é…ç½®ï¼‰
result = compiled_graph.invoke(
    batch_input,
    config={"recursion_limit": 50}  # å¯é…ç½®é€’å½’é™åˆ¶ç­‰å‚æ•°
)

print(f"å¤„ç†äº† {result['processed_count']} æ¡æ¶ˆæ¯")
print("å¤„ç†ç»“æœ:", result["messages"])
```

### ğŸ” Level 3: å¯¹æ¯”å­¦ä¹ ï¼ˆé¿å…é™·é˜±ï¼‰

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

class State(TypedDict):
    value: int

def increment(state: State) -> State:
    return {"value": state["value"] + 1}

graph = StateGraph(State)
graph.add_node("increment", increment)
graph.set_entry_point("increment")
graph.set_finish_point("increment")

# âŒ é”™è¯¯ç”¨æ³•ï¼šå¿˜è®°ç¼–è¯‘ç›´æ¥è°ƒç”¨
try:
    graph.invoke({"value": 1})  # ä¼šæŠ›å‡º AttributeError
except AttributeError as e:
    print(f"é”™è¯¯: {e}")

# âœ… æ­£ç¡®ç”¨æ³•ï¼šå…ˆç¼–è¯‘å†è°ƒç”¨
compiled_graph = graph.compile()
result = compiled_graph.invoke({"value": 1})
print(f"æ­£ç¡®ç»“æœ: {result}")  # è¾“å‡º: {'value': 2}

# âŒ é”™è¯¯ç”¨æ³•ï¼šé”™è¯¯çš„çŠ¶æ€ç»“æ„
try:
    compiled_graph.invoke({"wrong_field": 1})  # ç¼ºå°‘å¿…éœ€çš„ value å­—æ®µ
except Exception as e:
    print(f"çŠ¶æ€é”™è¯¯: {e}")

# âœ… æ­£ç¡®ç”¨æ³•ï¼šæä¾›å®Œæ•´çš„çŠ¶æ€
correct_result = compiled_graph.invoke({"value": 5})
print(f"æ­£ç¡®çŠ¶æ€çš„ç»“æœ: {correct_result}")
```

### ğŸš€ Level 4: å®æˆ˜åº”ç”¨ï¼ˆçœŸå®åœºæ™¯ï¼‰

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Literal
import json

class CustomerServiceState(TypedDict):
    user_query: str
    response: str
    sentiment: Literal["positive", "negative", "neutral"]
    processed: bool

def analyze_sentiment(state: CustomerServiceState) -> CustomerServiceState:
    """åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æƒ…æ„Ÿå€¾å‘"""
    query = state["user_query"].lower()
    if any(word in query for word in ["problem", "issue", "help", "urgent"]):
        sentiment = "negative"
    elif any(word in query for word in ["thank", "great", "awesome"]):
        sentiment = "positive"
    else:
        sentiment = "neutral"
    
    return {**state, "sentiment": sentiment}

def generate_response(state: CustomerServiceState) -> CustomerServiceState:
    """æ ¹æ®æƒ…æ„Ÿç”Ÿæˆç›¸åº”çš„å›å¤"""
    if state["sentiment"] == "negative":
        response = "I'm sorry you're experiencing issues. Let me help you resolve this problem."
    elif state["sentiment"] == "positive":
        response = "Thank you for your positive feedback! We're glad to hear you're enjoying our service."
    else:
        response = "Thank you for contacting us. How can I assist you today?"
    
    return {**state, "response": response, "processed": True}

# æ„å»ºå®¢æœå·¥ä½œæµ
graph = StateGraph(CustomerServiceState)
graph.add_node("sentiment_analysis", analyze_sentiment)
graph.add_node("response_generation", generate_response)

graph.add_edge("sentiment_analysis", "response_generation")
graph.add_edge("response_generation", END)
graph.set_entry_point("sentiment_analysis")

# ç¼–è¯‘å›¾
customer_service = graph.compile()

# æµ‹è¯•ä¸åŒåœºæ™¯
test_cases = [
    {"user_query": "I have a problem with my account", "response": "", "sentiment": "neutral", "processed": False},
    {"user_query": "This service is awesome!", "response": "", "sentiment": "neutral", "processed": False},
    {"user_query": "I need some information", "response": "", "sentiment": "neutral", "processed": False}
]

print("å®¢æœå·¥ä½œæµæµ‹è¯•ç»“æœ:")
print("-" * 50)

for i, test_case in enumerate(test_cases, 1):
    result = customer_service.invoke(test_case)
    print(f"æ¡ˆä¾‹ {i}:")
    print(f"  ç”¨æˆ·æŸ¥è¯¢: {result['user_query']}")
    print(f"  æƒ…æ„Ÿåˆ†æ: {result['sentiment']}")
    print(f"  ç”Ÿæˆå›å¤: {result['response']}")
    print(f"  å¤„ç†çŠ¶æ€: {'å·²å®Œæˆ' if result['processed'] else 'æœªå®Œæˆ'}")
    print("-" * 30)

# æµå¼æ‰§è¡Œæ¼”ç¤º
print("\næµå¼æ‰§è¡Œæ¼”ç¤º:")
negative_query = {"user_query": "This is urgent! I need help now!", "response": "", "sentiment": "neutral", "processed": False}
for step_name, step_output in graph.stream(negative_query):
    print(f"æ­¥éª¤ '{step_name}': {json.dumps(step_output, indent=2)}")
```

### ğŸ’¡ è®°å¿†è¦ç‚¹
- `compile()` æ˜¯å°†å›¾å®šä¹‰è½¬æ¢ä¸ºå¯æ‰§è¡Œå¯¹è±¡çš„å¿…è¦æ­¥éª¤ï¼Œå¿˜è®°ç¼–è¯‘æ˜¯å¸¸è§é”™è¯¯
- `stream()` æä¾›å®æ—¶æ‰§è¡Œç›‘æ§ï¼Œé€‚åˆè°ƒè¯•å’Œè§‚å¯Ÿå¤æ‚å·¥ä½œæµçš„æ‰§è¡Œè¿‡ç¨‹
- è¾“å…¥çŠ¶æ€å¿…é¡»ä¸å®šä¹‰çš„ State ç»“æ„å®Œå…¨åŒ¹é…ï¼Œå¦åˆ™ä¼šæŠ›å‡ºå¼‚å¸¸
- æµå¼æ‰§è¡Œè¿”å›ç”Ÿæˆå™¨ï¼Œå¯ä»¥é€æ­¥å¤„ç†æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡ºç»“æœ
- ç¼–è¯‘åçš„å›¾å¯ä»¥é‡å¤ä½¿ç”¨ï¼Œé€‚åˆå¤„ç†å¤šä¸ªè¾“å…¥è¯·æ±‚