{
  "chapters": [
    {
      "title": "第一章: NLP基石：从文本到向量",
      "id": "outline-ch-1",
      "groups": [
        {
          "title": "1.1 文本预处理：从原始语料到结构化词元",
          "id": "outline-gr-1-1",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "1.1.1 起点：为何机器无法直接阅读文本？",
              "id": "outline-sec-1-1-1-1.1.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.1.2 第一步：基础清洗 (Data Cleaning)",
              "id": "outline-sec-1-1-2-1.1.2-data-cleaning",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.1.3 第二步：文本切分 (Tokenization)",
              "id": "outline-sec-1-1-3-1.1.3-tokenization",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.1.4 深入探索：处理未登录词的子词切分 (Subword Tokenization)",
              "id": "outline-sec-1-1-4-1.1.4-subword-tokenization",
              "relation_to_previous": "deep_dive_into",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.1.5 第三步：词元标准化 (Stemming, Lemmatization & Stop Words)",
              "id": "outline-sec-1-1-5-1.1.5-stemming-lemmatization-stop-words",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "1.2 向量化表示：赋予词语数学形态",
          "id": "outline-gr-1-2",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "1.2.1 核心思想：向量空间模型 (Vector Space Model)",
              "id": "outline-sec-1-2-1-1.2.1-vector-space-model",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.2.2 工具一 (离散表示)：词袋模型 (Bag-of-Words)",
              "id": "outline-sec-1-2-2-1.2.2-bag-of-words",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.2.3 改进：从词频(BoW)到TF-IDF权重",
              "id": "outline-sec-1-2-3-1.2.3-bowtf-idf",
              "relation_to_previous": "deep_dive_into",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.2.4 工具二 (分布式表示)：词嵌入 (Word Embedding)",
              "id": "outline-sec-1-2-4-1.2.4-word-embedding",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "1.2.5 经典实现：深入Word2Vec与GloVe",
              "id": "outline-sec-1-2-5-1.2.5-word2vecglove",
              "relation_to_previous": "deep_dive_into",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": true,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        }
      ],
      "objective": "掌握将非结构化文本转化为计算机可处理的结构化特征的核心流程，并理解从经典词袋模型到现代词嵌入的表示方法。"
    },
    {
      "title": "第二章: 序列建模演进：从RNN到Transformer",
      "id": "outline-ch-2",
      "groups": [
        {
          "title": "2.1 循环神经网络 (RNN)：序列记忆的首次尝试",
          "id": "outline-gr-2-1",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "2.1.1 核心挑战：如何让神经网络处理序列数据",
              "id": "outline-sec-2-1-1-2.1.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.1.2 RNN的解决方案：引入“隐藏状态”实现记忆",
              "id": "outline-sec-2-1-2-2.1.2-rnn",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.1.3 根本缺陷：长程依赖与梯度消失/爆炸问题",
              "id": "outline-sec-2-1-3-2.1.3",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "2.2 长短期记忆网络 (LSTM)：攻克RNN的记忆难题",
          "id": "outline-gr-2-2",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "2.2.1 破局之道：用“门控机制”精细控制信息流",
              "id": "outline-sec-2-2-1-2.2.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.2.2 深度解析：遗忘门、输入门与输出门的协同工作",
              "id": "outline-sec-2-2-2-2.2.2",
              "relation_to_previous": "deep_dive_into",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "2.3 Seq2Seq框架：编码器-解码器模型的局限",
          "id": "outline-gr-2-3",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "2.3.1 架构总览：将输入序列映射到输出序列的通用范式",
              "id": "outline-sec-2-3-1-2.3.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.3.2 症结所在：固定长度上下文向量的“信息瓶颈”",
              "id": "outline-sec-2-3-2-2.3.2",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "2.4 注意力机制：打破信息瓶颈的革命",
          "id": "outline-gr-2-4",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "2.4.1 革命性思想：让解码器“关注”输入的特定部分",
              "id": "outline-sec-2-4-1-2.4.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.4.2 机制详解：Query, Key, Value的角色与计算过程",
              "id": "outline-sec-2-4-2-2.4.2-query-key-value",
              "relation_to_previous": "deep_dive_into",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "2.5 Transformer架构：注意力就是你所需的一切",
          "id": "outline-gr-2-5",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "2.5.1 范式转换：彻底告别循环，拥抱并行计算",
              "id": "outline-sec-2-5-1-2.5.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.5.2 核心构件一：自注意力机制 (Self-Attention)",
              "id": "outline-sec-2-5-2-2.5.2-self-attention",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.5.3 核心构件二：多头注意力机制 (Multi-Head Attention)",
              "id": "outline-sec-2-5-3-2.5.3-multi-head-attention",
              "relation_to_previous": "deep_dive_into",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.5.4 核心构件三：位置编码 (Positional Encoding)",
              "id": "outline-sec-2-5-4-2.5.4-positional-encoding",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "2.5.5 整体蓝图：Encoder与Decoder的堆叠与连接",
              "id": "outline-sec-2-5-5-2.5.5-encoderdecoder",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": true
              }
            }
          ]
        }
      ],
      "objective": "理解循环神经网络（RNN/LSTM）处理序列数据的基本原理及其局限性，并掌握作为现代NLP基石的注意力机制与Transformer架构。"
    },
    {
      "title": "第三章: 预训练革命：BERT与GPT的设计哲学",
      "id": "outline-ch-3",
      "groups": [
        {
          "title": "3.1 革命前夜：从序列依赖到注意力机制",
          "id": "outline-gr-3-1",
          "structure_type": "pipeline",
          "sections": []
        },
        {
          "title": "3.2 “预训练-微调”范式：BERT与GPT的双雄时代",
          "id": "outline-gr-3-2",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "3.2.1 核心思想：迁移学习与“预训练-微调”范式",
              "id": "outline-sec-3-2-1-3.2.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "3.2.2 工具一 (编码器)：BERT如何通过双向上下文理解语言",
              "id": "outline-sec-3-2-2-3.2.2-bert",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "3.2.3 工具二 (解码器)：GPT如何通过自回归生成流畅文本",
              "id": "outline-sec-3-2-3-3.2.3-gpt",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "3.2.4 深度对比：不同预训练目标与适用场景的剖析",
              "id": "outline-sec-3-2-4-3.2.4",
              "relation_to_previous": "deep_dive_into",
              "archetype": "comparative_analysis",
              "switches": {
                "include_comparison_table": true,
                "include_code": false,
                "tone_style": "analysis",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "3.3 驾驭巨人：与大模型协作的艺术",
          "id": "outline-gr-3-3",
          "structure_type": "pipeline",
          "sections": []
        },
        {
          "title": "3.4 LLM时代：挑战、对策与未来",
          "id": "outline-gr-3-4",
          "structure_type": "toolbox",
          "sections": []
        }
      ],
      "objective": "领会迁移学习在NLP中的威力，并深入剖析以BERT为代表的编码器模型和以GPT为代表的解码器模型的架构差异与应用场景。"
    },
    {
      "title": "第四章: 大语言模型（LLM）时代：提示、微调与增强",
      "id": "outline-ch-4",
      "groups": [
        {
          "title": "4.1 驾驭LLM的基础：从对话式交互到上下文学习",
          "id": "outline-gr-4-1",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "4.1.1 范式转移：为何与LLM交互是门新艺术",
              "id": "outline-sec-4-1-1-4.1.1-llm",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.1.2 核心能力：上下文学习 (In-Context Learning)",
              "id": "outline-sec-4-1-2-4.1.2-in-context-learning",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.1.3 基本功：提示工程 (Prompt Engineering) 概览",
              "id": "outline-sec-4-1-3-4.1.3-prompt-engineering",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "4.2 提示工程工具箱：设计高效的指令",
          "id": "outline-gr-4-2",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "4.2.1 基础提示：明确角色、任务与格式",
              "id": "outline-sec-4-2-1-4.2.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.2.2 技巧一：零样本 (Zero-shot) 与少样本 (Few-shot) 提示",
              "id": "outline-sec-4-2-2-4.2.2-zero-shot-few-shot",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "case_study",
              "switches": {
                "include_case_snippets": true,
                "include_code": false,
                "tone_style": "narrative",
                "include_mermaid": true,
                "diagram_types": [
                  "gantt"
                ],
                "diagram_depth": "light"
              }
            },
            {
              "title": "4.2.3 技巧二：思维链 (Chain-of-Thought) 激发推理能力",
              "id": "outline-sec-4-2-3-4.2.3-chain-of-thought",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "case_study",
              "switches": {
                "include_case_snippets": true,
                "include_code": false,
                "tone_style": "narrative",
                "include_mermaid": true,
                "diagram_types": [
                  "gantt"
                ],
                "diagram_depth": "light"
              }
            },
            {
              "title": "4.2.4 常见陷阱：提示的脆弱性 (Prompt Brittleness) 与规避",
              "id": "outline-sec-4-2-4-4.2.4-prompt-brittleness",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "4.3 模型微调流水线：用私有数据塑造专属LLM",
          "id": "outline-gr-4-3",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "4.3.1 何时需要微调：超越提示工程的边界",
              "id": "outline-sec-4-3-1-4.3.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.3.2 第一步：准备高质量的领域数据集",
              "id": "outline-sec-4-3-2-4.3.2",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.3.3 第二步：选择基座模型与执行训练 (以Hugging Face为例)",
              "id": "outline-sec-4-3-3-4.3.3-hugging-face",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "技巧升级：参数高效微调 (PEFT) 与LoRA",
              "goal": "掌握在有限资源下微调大模型的核心技术LoRA，理解其原理与优势。",
              "difficulty": "intermediate",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": true,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              },
              "id": "outline-sec-new-peft-lora-5"
            },
            {
              "title": "4.3.4 第三步：评估、部署与关键挑战 (如灾难性遗忘)",
              "id": "outline-sec-4-3-4-4.3.4",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "4.4 检索增强生成 (RAG)：为LLM注入实时知识",
          "id": "outline-gr-4-4",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "4.4.1 核心痛点：解决模型的知识局限与“幻觉”问题",
              "id": "outline-sec-4-4-1-4.4.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.4.2 流程解析一：构建可检索的知识库 (向量化与向量数据库)",
              "id": "outline-sec-4-4-2-4.4.2",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.4.3 流程解析二：检索、增强与生成",
              "id": "outline-sec-4-4-3-4.4.3",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.4.4 实践框架：使用LangChain快速搭建RAG应用",
              "id": "outline-sec-4-4-4-4.4.4-langchainrag",
              "relation_to_previous": "deep_dive_into",
              "archetype": "api_quickstart",
              "switches": {
                "include_code": true,
                "code_lang": null,
                "include_references": true,
                "tone_style": "quickstart",
                "include_mermaid": false,
                "diagram_types": [
                  "sequence"
                ],
                "diagram_depth": "light"
              }
            }
          ]
        },
        {
          "title": "4.5 前沿展望：从增强模型到自主代理",
          "id": "outline-gr-4-5",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "4.5.1 迈向自主：AI代理 (AI Agents) 的概念与潜力",
              "id": "outline-sec-4-5-1-4.5.1-ai-ai-agents",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.5.2 安全与对齐：宪法AI (Constitutional AI) 与可解释性 (XAI)",
              "id": "outline-sec-4-5-2-4.5.2-ai-constitutional-ai-xai",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "4.5.3 超越文本：多模态 (Multimodality) 的融合",
              "id": "outline-sec-4-5-3-4.5.3-multimodality",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        }
      ],
      "objective": "学习驾驭大型语言模型的核心技术，包括如何设计高效的提示（Prompting）、如何利用私有数据进行微调（Fine-tuning），以及如何通过RAG等技术增强模型能力。"
    },
    {
      "title": "第五章: NLP工程实践：工具、流程与生产化",
      "id": "outline-ch-5",
      "groups": [
        {
          "title": "5.1 现代NLP开发蓝图：从模型到应用",
          "id": "outline-gr-5-1",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "5.1.1 范式变迁：从零训练到迁移学习",
              "id": "outline-sec-5-1-1-5.1.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.1.2 核心流程：定义问题、准备数据、选择模型、评估上线",
              "id": "outline-sec-5-1-2-5.1.2",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.1.3 生态概览：认识三大核心角色 (PyTorch/TF, Hugging Face, LangChain)",
              "id": "outline-sec-5-1-3-5.1.3-pytorchtf-hugging-face-langchain",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "5.2 底层引擎：选择你的深度学习框架",
          "id": "outline-gr-5-2",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "5.2.1 为何需要框架：张量计算与自动微分",
              "id": "outline-sec-5-2-1-5.2.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.2.2 学术界宠儿：PyTorch的灵活性与动态图",
              "id": "outline-sec-5-2-2-5.2.2-pytorch",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.2.3 工业界标配：TensorFlow/Keras的生产力与生态",
              "id": "outline-sec-5-2-3-5.2.3-tensorflowkeras",
              "relation_to_previous": "alternative_to",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "5.3 效率倍增器：深入Hugging Face全家桶",
          "id": "outline-gr-5-3",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "5.3.1 核心理念：模型、数据集、分词器的民主化",
              "id": "outline-sec-5-3-1-5.3.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.3.2 工具一：`transformers` - 即插即用的预训练模型库",
              "id": "outline-sec-5-3-2-5.3.2-transformers",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.3.3 工具二：`datasets` & `tokenizers` - 标准化的数据处理",
              "id": "outline-sec-5-3-3-5.3.3-datasets-tokenizers",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.3.4 工具三：The Hub - 全球最大的AI开源社区",
              "id": "outline-sec-5-3-4-5.3.4-the-hub---ai",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "5.4 实战演练：端到端情感分类模型微调",
          "id": "outline-gr-5-4",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "5.4.1 第一步：数据清洗与预处理",
              "id": "outline-sec-5-4-1-5.4.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.4.2 第二步：选择预训练模型并进行微调 (Fine-tuning)",
              "id": "outline-sec-5-4-2-5.4.2-fine-tuning",
              "relation_to_previous": "builds_on",
              "archetype": "api_quickstart",
              "switches": {
                "include_code": true,
                "code_lang": null,
                "include_references": true,
                "tone_style": "quickstart",
                "include_mermaid": false,
                "diagram_types": [
                  "sequence"
                ],
                "diagram_depth": "light"
              }
            },
            {
              "title": "5.4.3 第三步：模型评估与错误分析 (Evaluation & Error Analysis)",
              "id": "outline-sec-5-4-3-5.4.3-evaluation-error-analysis",
              "relation_to_previous": "builds_on",
              "archetype": "procedure_checklist",
              "switches": {
                "include_steps_checklist": true,
                "include_code": false,
                "tone_style": "tutorial",
                "include_mermaid": true,
                "diagram_types": [
                  "flowchart"
                ],
                "diagram_depth": "light"
              }
            },
            {
              "title": "5.4.4 第四步：实验跟踪与版本管理 (WandB)",
              "id": "outline-sec-5-4-4-5.4.4-wandb",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "5.5 前沿范式：构建LLM驱动的智能应用",
          "id": "outline-gr-5-5",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "5.5.5 未来趋势：从应用到自主智能体 (AI Agents)",
              "id": "outline-sec-5-5-5-5.5.5-ai-agents",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "5.6 生产环境的挑战：性能、风险与可信赖AI",
          "id": "outline-gr-5-6",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "5.6.1 导论：从“能用”到“好用”的最后几公里",
              "id": "outline-sec-5-6-1-5.6.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.6.2 性能考量：计算成本、效率与模型压缩",
              "id": "outline-sec-5-6-2-5.6.2",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.6.3 结果可靠性：警惕幻觉、偏见与虚假相关",
              "id": "outline-sec-5-6-3-5.6.3",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.6.4 评估陷阱：避免数据泄露与评估指标误用",
              "id": "outline-sec-5-6-4-5.6.4",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "5.6.5 建立信任：可解释AI (XAI) 的初步探索",
              "id": "outline-sec-5-6-5-5.6.5-ai-xai",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        }
      ],
      "objective": "熟悉Hugging Face、PyTorch/TensorFlow、LangChain等业界标准工具，并掌握评估模型性能、构建端到端NLP应用的基本能力。"
    },
    {
      "title": "第六章: 前沿、挑战与伦理：负责任地使用NLP",
      "id": "outline-ch-6",
      "groups": [
        {
          "title": "6.1 前沿趋势：从语言模型到世界模型",
          "id": "outline-gr-6-1",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "6.1.1 导论：LLM开启的新范式",
              "id": "outline-sec-6-1-1-6.1.1-llm",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.1.2 工具一 (行动力)：AI代理 (AI Agents) - 自主规划与执行",
              "id": "outline-sec-6-1-2-6.1.2-ai-ai-agents",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.1.3 工具二 (感知力)：多模态 (Multimodality) - 超越文本的理解",
              "id": "outline-sec-6-1-3-6.1.3-multimodality",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.1.4 工具三 (知识力)：检索增强生成 (RAG) - 结合外部知识",
              "id": "outline-sec-6-1-4-6.1.4-rag",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.1.5 工具四 (推理力)：思维链 (Chain-of-Thought) - 提升复杂推理能力",
              "id": "outline-sec-6-1-5-6.1.5-chain-of-thought",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.1.6 趋势探讨：走向更高效、更普及的模型 (SLMs & Efficient Transformers)",
              "id": "outline-sec-6-1-6-6.1.6-slms-efficient-transformers",
              "relation_to_previous": "deep_dive_into",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "6.2 核心挑战：大型模型固有的阴暗面",
          "id": "outline-gr-6-2",
          "structure_type": "toolbox",
          "sections": [
            {
              "title": "6.2.1 导论：能力越大，风险越大",
              "id": "outline-sec-6-2-1-6.2.1",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.2.2 挑战一 (事实性)：幻觉 (Hallucination) - 自信地编造事实",
              "id": "outline-sec-6-2-2-6.2.2-hallucination",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.2.3 挑战二 (社会性)：偏见 (Bias) - 学习并放大社会刻板印象",
              "id": "outline-sec-6-2-3-6.2.3-bias",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.2.4 挑战三 (稳定性)：提示词脆弱性 (Prompt Brittleness) - 输出的不可预测",
              "id": "outline-sec-6-2-4-6.2.4-prompt-brittleness",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.2.5 挑战四 (透明度)：缺乏可解释性 (Lack of Interpretability) - 黑箱决策的困境",
              "id": "outline-sec-6-2-5-6.2.5-lack-of-interpretability",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.2.6 挑战五 (资源性)：高昂的计算成本与环境影响",
              "id": "outline-sec-6-2-6-6.2.6",
              "relation_to_previous": "tool_in_toolbox",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        },
        {
          "title": "6.3 行动框架：构建负责任且可信赖的AI",
          "id": "outline-gr-6-3",
          "structure_type": "pipeline",
          "sections": [
            {
              "title": "6.3.1 第一步 (诊断)：通过可解释AI (XAI) 理解模型决策",
              "id": "outline-sec-6-3-1-6.3.1-ai-xai",
              "relation_to_previous": "first_in_sequence",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.3.2 第二步 (对齐)：利用人类反馈与宪法AI (CAI) 引导模型行为",
              "id": "outline-sec-6-3-2-6.3.2-ai-cai",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.3.3 第三步 (实践)：在开发中融入系统性错误分析与领域自适应",
              "id": "outline-sec-6-3-3-6.3.3",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            },
            {
              "title": "6.3.4 第四步 (愿景)：推动技术普惠 (低资源NLP) 与公平性",
              "id": "outline-sec-6-3-4-6.3.4-nlp",
              "relation_to_previous": "builds_on",
              "archetype": "concept_exposition",
              "switches": {
                "include_code": false,
                "include_case_snippets": false,
                "tone_style": "expository",
                "include_mermaid": false
              }
            }
          ]
        }
      ],
      "objective": "了解AI代理、多模态等前沿趋势，同时批判性地认识NLP技术存在的偏见、幻觉等挑战，培养负责任的AI开发思维。"
    }
  ],
  "meta": {
    "topic": "自然语言处理",
    "topic_slug": "outline",
    "schema_version": "pipeline.v1"
  }
}